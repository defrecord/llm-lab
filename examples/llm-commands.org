#+TITLE: LLM Command Examples
#+PROPERTY: header-args :mkdirp yes :results output :exports both

* Prompt Examples
#+begin_src sh :tangle data/example-haiku.sh :mkdirp t
llm "Write a haiku about debugging" | tee data/example-haiku.md | head 
#+end_src

#+RESULTS:

* Alias Management 
#+begin_src sh 
llm aliases list
#+end_src

#+RESULTS:
#+begin_example
4o                  : gpt-4o
4o-mini             : gpt-4o-mini
3.5                 : gpt-3.5-turbo
chatgpt             : gpt-3.5-turbo
chatgpt-16k         : gpt-3.5-turbo-16k
3.5-16k             : gpt-3.5-turbo-16k
4                   : gpt-4
gpt4                : gpt-4
4-32k               : gpt-4-32k
gpt-4-turbo-preview : gpt-4-turbo
4-turbo             : gpt-4-turbo
4t                  : gpt-4-turbo
3.5-instruct        : gpt-3.5-turbo-instruct
chatgpt-instruct    : gpt-3.5-turbo-instruct
g15                 : gemini-1.5-pro-latest
ada                 : text-embedding-ada-002 (embedding)
ada-002             : text-embedding-ada-002 (embedding)
3-small             : text-embedding-3-small (embedding)
3-large             : text-embedding-3-large (embedding)
3-small-512         : text-embedding-3-small-512 (embedding)
3-large-256         : text-embedding-3-large-256 (embedding)
3-large-1024        : text-embedding-3-large-1024 (embedding)
#+end_example

#+begin_src sh 
llm aliases set g15 gemini-1.5-pro-latest
#+end_src

#+RESULTS:

* Chat Sessions
#+begin_src sh
llm chat -m gemini-1.5-pro-latest
#+end_src

* Embeddings
#+begin_src sh
llm embed "Some text to embed" -m text-embedding-3-small
#+end_src

#+RESULTS:

* Model Management
#+begin_src sh
llm models list 
#+end_src

#+RESULTS:
#+begin_example
OpenAI Chat: gpt-4o (aliases: 4o)
OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)
OpenAI Chat: gpt-4o-audio-preview
OpenAI Chat: gpt-4o-audio-preview-2024-12-17
OpenAI Chat: gpt-4o-audio-preview-2024-10-01
OpenAI Chat: gpt-4o-mini-audio-preview
OpenAI Chat: gpt-4o-mini-audio-preview-2024-12-17
OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)
OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)
OpenAI Chat: gpt-4 (aliases: 4, gpt4)
OpenAI Chat: gpt-4-32k (aliases: 4-32k)
OpenAI Chat: gpt-4-1106-preview
OpenAI Chat: gpt-4-0125-preview
OpenAI Chat: gpt-4-turbo-2024-04-09
OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)
OpenAI Chat: o1
OpenAI Chat: o1-2024-12-17
OpenAI Chat: o1-preview
OpenAI Chat: o1-mini
OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)
GeminiPro: gemini-pro
GeminiPro: gemini-1.5-pro-latest (aliases: g15)
GeminiPro: gemini-1.5-flash-latest
GeminiPro: gemini-1.5-pro-001
GeminiPro: gemini-1.5-flash-001
GeminiPro: gemini-1.5-pro-002
GeminiPro: gemini-1.5-flash-002
GeminiPro: gemini-1.5-flash-8b-latest
GeminiPro: gemini-1.5-flash-8b-001
GeminiPro: gemini-exp-1114
GeminiPro: gemini-exp-1121
GeminiPro: gemini-exp-1206
GeminiPro: gemini-2.0-flash-exp
GeminiPro: learnlm-1.5-pro-experimental
GeminiPro: gemini-2.0-flash-thinking-exp-1219
GeminiPro: gemini-2.0-flash-thinking-exp-01-21
Default: gpt-4o-mini
#+end_example

#+begin_src sh 
llm models list | grep "^Gemini"
#+end_src

#+RESULTS:
#+begin_example
GeminiPro: gemini-pro
GeminiPro: gemini-1.5-pro-latest (aliases: g15)
GeminiPro: gemini-1.5-flash-latest
GeminiPro: gemini-1.5-pro-001
GeminiPro: gemini-1.5-flash-001
GeminiPro: gemini-1.5-pro-002
GeminiPro: gemini-1.5-flash-002
GeminiPro: gemini-1.5-flash-8b-latest
GeminiPro: gemini-1.5-flash-8b-001
GeminiPro: gemini-exp-1114
GeminiPro: gemini-exp-1121
GeminiPro: gemini-exp-1206
GeminiPro: gemini-2.0-flash-exp
GeminiPro: learnlm-1.5-pro-experimental
GeminiPro: gemini-2.0-flash-thinking-exp-1219
GeminiPro: gemini-2.0-flash-thinking-exp-01-21
#+end_example


#+begin_src shell
llm models default gemini-2.0-flash-thinking-exp-01-21
#+end_src


#+RESULTS:

* Templates
#+begin_src sh
llm templates list
#+end_src

#+RESULTS:
#+begin_example
clojure-function : system: Write a pure Clojure function following functional...
commit           : system: Create a conventional commit message for provided ...
elisp-function   : system: Write an Emacs Lisp function following elisp conve...
go-function      : system: Write an idiomatic Go function following Go style ...
js-function      : system: Write a modern JavaScript function using ES6+ feat...
python-function  : system: Write a clean, well-documented Python function tha...
python-template  : system: Write Python code
rust-function    : system: Write a safe Rust function with proper error handl...
scheme-function  : system: Write a Scheme function following R6RS conventions...
session-agent    : system: # Session Agent v1.0 A context-aware workflow trac...
#+end_example

#+begin_src sh 
llm --system "Write Python code" --save python-template
#+end_src

#+RESULTS:

** Session Agent 

#+begin_src sh
cat ../prompts/session-agent.md | head
llm --save session-agent --model gemini-2.0-flash-exp --system "$(cat ../prompts/session-agent.md)"
#+end_src

#+RESULTS:
#+begin_example
# Session Agent v1.0
A context-aware workflow tracking and task management system that integrates with Workspace, Keep, and Gemini.

## Core Principles
1. Default to silent logging with timestamps
2. Minimize unnecessary responses
3. Preserve essential context
4. Maintain state across platforms
5. Allow meta-level configuration

#+end_example


#+begin_src sh 
echo "Reviewing LLM commands as $USER on `hostname` `uname -a`" | llm -t session-agent | head 
#+end_src

#+begin_src sh 
llm -t session-agent "Reviewing LLM commands as $USER on `hostname` `uname -a`" | head 
#+end_src

#+RESULTS:

#+begin_src sh 
llm chat -t session-agent -m gemini-2.0-flash-exp
#+end_src

#+RESULTS:
** Conventional Commits

#+begin_src shell
llm --save commit --model gemini-2.0-flash-exp --system "Create a conventional commit message for provided diff"
#+end_src

#+RESULTS:
#+begin_src shell
git diff --staged | llm -t commit 

#+end_src

* Logs & History
#+begin_src sh
llm logs -c | head
#+end_src

#+RESULTS:
#+begin_example
# 2025-01-31T19:09:40    conversation: 01jjywa3kq08xjmbkwrfqrqnmv

Model: **gemini-2.0-flash-thinking-exp-01-21**

## Prompt:

Reviewing LLM commands as jwalsh on jasons-mbp-2.lan Darwin jasons-mbp-2.lan 19.6.0 Darwin Kernel Version 19.6.0: Tue Jun 21 21:18:39 PDT 2022; root:xnu-6153.141.66~1/RELEASE_X86_64 x86_64

## System:

#+end_example

#+begin_src sh 
 llm logs --json | jq -r '.[]|.model'  | sort | uniq -c | sort -rn
#+end_src

#+RESULTS:
:    2 gemini-2.0-flash-thinking-exp-01-21
:    1 gemini-1.5-pro-latest

