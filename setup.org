#+TITLE: LLM Lab Setup
#+PROPERTY: header-args :mkdirp yes :tangle yes

* Package Management
:PROPERTIES:
:header-args: :mkdirp t :tangle pyproject.toml
:END:

#+begin_src toml
[project]
name = "llm-lab"
version = "0.1.0"
description = "Testing environment for exploring LLM CLI tools"
requires-python = ">=3.11"
dependencies = [
    "llm",
    "ttok",
    "strip-tags",
    "llm-gemini",
    "llm-bedrock",
    "llm-claude",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "black",
    "isort",
    "mypy",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
#+end_src

* Base Structure
:PROPERTIES:
:header-args: :mkdirp t :tangle src/llm_lab/__init__.py
:END:

#+begin_src python
"""LLM Lab - Testing environment for LLM tools."""
__version__ = "0.1.0"

from pathlib import Path

ROOT_DIR = Path(__file__).parent.parent.parent
CONFIG_DIR = ROOT_DIR / "config"
TEMPLATES_DIR = ROOT_DIR / "templates"
#+end_src

* Configuration
:PROPERTIES:
:header-args: :mkdirp t :tangle config/default.yaml
:END:

#+begin_src yaml
providers:
  ollama:
    default_model: deepseek-coder
    models:
      - deepseek-coder
      - llama2
      - codellama
      - llava
  gemini:
    default_model: gemini-1.5-pro-latest
    models:
      - gemini-1.5-pro-latest
      - gemini-1.5-flash-latest
  claude:
    default_model: claude-3
  openai:
    default_model: gpt-4
    
templates:
  path: templates
  default_format: markdown
  
processing:
  max_tokens: 4000
  strip_tags_selectors:
    - article
    - .content
    - main
#+end_src

* Templates
:PROPERTIES:
:header-args: :mkdirp t :tangle templates/basic.yaml
:END:

#+begin_src yaml
name: basic_template
description: Basic analysis template
version: "1.0.0"
parameters:
  - name: input
    type: string
    required: true
  - name: format
    type: string
    default: markdown
  - name: ground_truth
    type: boolean
    default: false
provider_options:
  gemini:
    model: gemini-1.5-pro-latest
    google_search: "{ground_truth}"
  claude:
    model: claude-3
  openai:
    model: gpt-4
prompt: |
  Analyze the following content:
  
  {input}
  
  Provide:
  1. Key points
  2. Main themes
  3. Supporting evidence
  4. Conclusions
  
  Format as: {format}
#+end_src

* Tests
:PROPERTIES:
:header-args: :mkdirp t :tangle tests/test_basic.py
:END:

#+begin_src python
"""Basic test suite for LLM Lab."""
from pathlib import Path
import pytest
import yaml

from llm_lab import ROOT_DIR, CONFIG_DIR, TEMPLATES_DIR

def test_config_exists():
    """Test that default config exists."""
    assert (CONFIG_DIR / "default.yaml").exists()

def test_template_exists():
    """Test that basic template exists."""
    assert (TEMPLATES_DIR / "basic.yaml").exists()

def test_template_valid():
    """Test that basic template is valid."""
    with open(TEMPLATES_DIR / "basic.yaml") as f:
        template = yaml.safe_load(f)
    assert "name" in template
    assert "parameters" in template
    assert any(p["name"] == "input" for p in template["parameters"])
#+end_src

* Dev Setup
:PROPERTIES:
:header-args: :mkdirp t :tangle .envrc
:END:

#+begin_src sh
# Provider API Keys
export OPENAI_API_KEY=""
export ANTHROPIC_API_KEY=""
export GOOGLE_AI_API_KEY=""
export AWS_ACCESS_KEY_ID=""
export AWS_SECRET_ACCESS_KEY=""
export AWS_REGION="us-west-2"

# Development
layout python3
export PYTHONPATH="$PWD/src:$PYTHONPATH"
export UV_SYSTEM_PYTHON=1

# Use UV for package management
use uv
#+end_src
